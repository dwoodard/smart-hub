networks:
  webui-network:
    # Define the custom network

volumes:
  n8n_storage:
  postgres_storage:
  ollama_storage:
  qdrant_storage:
  open-webui:
  n8n_backup:
  shared_storage:


services:
  # Open Web UI Service

  # open-webui:
  #   image: ghcr.io/open-webui/open-webui:main
  #   container_name: open-webui
  #   ports:
  #     - "3000:8080"
  #   volumes:
  #     - ollama_storage:/root/.ollama
  #     - open-webui:/app/backend/data
  #   environment:
  #     - OLLAMA_BASE_URL=http://ollama:11434
  #   networks:
  #     - webui-network
  #   restart: always

  # Postgres Database for n8n
  postgres:
    image: postgres:16-alpine
    restart: always
    ports:
      - "5433:5432"
    env_file: .env
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-root}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-root}
      - POSTGRES_DB=${POSTGRES_DB:-n8n}
    volumes:
      - postgres_storage:/var/lib/postgresql/data
    networks:
      - webui-network
    healthcheck:
      test: [ 'CMD-SHELL', 'pg_isready -h localhost -U ${POSTGRES_USER:-root} -d ${POSTGRES_DB:-n8n}' ]
      interval: 5s
      timeout: 5s
      retries: 10

  # Main n8n Service
  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_USER=root
      - DB_POSTGRESDB_PASSWORD=root
      - N8N_DIAGNOSTICS_ENABLED=false
      - N8N_PERSONALIZATION_ENABLED=false
      - N8N_ENCRYPTION_KEY
      - N8N_USER_MANAGEMENT_JWT_SECRET
      - N8N_SECURE_COOKIE=false
    restart: always
    ports:
      - "5678:5678"
    volumes:
      - n8n_storage:/home/node/.n8n
      - n8n_backup:/backup
      - shared_storage:/data/shared
    networks:
      - webui-network # Add the same network here
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:5678 || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 3

  # # Ollama Service
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   ports:
  #     - "11434:11434" # Ensure the port mapping is correct
  #   volumes:
  #     - ollama_storage:/root/.ollama
  #   entrypoint: [ "bash", "-c", "sleep 3;ollama pull llama3.2; ollama serve;" ] #ollama pull llama3.2
  #   networks:
  #     - webui-network # Ensure this service is on the same network
  #   restart: always

  # Qdrant Vector Database
  qdrant:
    image: qdrant/qdrant
    container_name: qdrant
    restart: always
    ports:
      - "6333:6333"
    volumes:
      - qdrant_storage:/qdrant/storage
    networks:
      - webui-network
  # SearxNG Service

  # searxng:
  #   image: searxng/searxng
  #   container_name: searxng
  #   ports:
  #     - "8888:8080"
  #   networks:
  #     - webui-network
  #   restart: always
